{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67199730",
   "metadata": {},
   "source": [
    "## Evidently configuration Guide\n",
    "\n",
    "This notebook demonstrates the basic usage of the `evidently` library. We'll cover:\n",
    "\n",
    "- Logging test cases  \n",
    "- Running evaluations  \n",
    "- Viewing and saving results locally  \n",
    "- Evaluating Evidently metrics through the Trace metrics API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751325ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install -U evidently pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4b70c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.9\n"
     ]
    }
   ],
   "source": [
    "import evidently\n",
    "print(evidently.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e51b6b0",
   "metadata": {},
   "source": [
    "### Imports Explained\n",
    "\n",
    "This script uses the **Evidently** library to evaluate LLM (Large Language Model) outputs using a variety of built-in descriptors. Here’s a breakdown of what each import does:\n",
    "\n",
    "\n",
    "#### Evidently Core\n",
    "\n",
    "```python\n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "```\n",
    "\n",
    "- **`Dataset`**: Represents the input data for evaluation (typically a `pandas.DataFrame`).\n",
    "- **`DataDefinition`**: Defines the structure of the dataset (e.g., which column contains the output text, reference, context, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "#### Evidently Descriptors\n",
    "\n",
    "```python\n",
    "from evidently.descriptors import (\n",
    "    DeclineLLMEval,\n",
    "    Sentiment,\n",
    "    TextLength,\n",
    "    NegativityLLMEval,\n",
    "    PIILLMEval,\n",
    "    BiasLLMEval,\n",
    "    ToxicityLLMEval,\n",
    "    ContextQualityLLMEval,\n",
    "    ContextRelevance\n",
    ")\n",
    "```\n",
    "\n",
    "These are **prebuilt descriptors** that evaluate specific aspects of LLM-generated responses:\n",
    "\n",
    "- **`DeclineLLMEval`**: Detects if the model declined to answer (e.g., refused or deferred).\n",
    "- **`Sentiment`**: Analyzes the sentiment (positive, neutral, or negative) of the output.\n",
    "- **`TextLength`**: Measures the number of words or characters in the text.\n",
    "- **`NegativityLLMEval`**: Evaluates the level of negativity in the generated text.\n",
    "- **`PIILLMEval`**: Detects whether Personally Identifiable Information (PII) is present.\n",
    "- **`BiasLLMEval`**: Detects possible social, cultural, or political biases in responses.\n",
    "- **`ToxicityLLMEval`**: Identifies toxic or harmful content in the output.\n",
    "- **`ContextQualityLLMEval`**: Measures how well the context is used or preserved in the output.\n",
    "- **`ContextRelevance`**: Evaluates whether the response is relevant to the provided context.\n",
    "\n",
    "---\n",
    "\n",
    "These descriptors allow automated, explainable evaluation of LLM responses using a consistent and extensible framework.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "from evidently.descriptors import  DeclineLLMEval, Sentiment, TextLength, NegativityLLMEval,PIILLMEval, BiasLLMEval, ToxicityLLMEval, ContextQualityLLMEval, ContextRelevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e28448",
   "metadata": {},
   "source": [
    "### Preparing a Dummy Dataset for Testing\n",
    "\n",
    "In this section, we create a sample dataset using Python lists and convert it into a `pandas.DataFrame` for testing purposes.\n",
    "\n",
    "Each entry in the dataset contains:\n",
    "- **`question`**: A user query or prompt.\n",
    "- **`answer`**: The model-generated response.\n",
    "- **`context`**: Supporting or reference information to evaluate against.\n",
    "\n",
    "This dummy dataset will be used for evaluating various LLM metrics such as relevance, factual correctness, and tone using Evidently descriptors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ef0bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the chemical symbol for gold?</td>\n",
       "      <td>Gold chemical symbol is Au.</td>\n",
       "      <td>Gold is a chemical element with the symbol Au ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Japan?</td>\n",
       "      <td>The capital of Japan is Tokyo.</td>\n",
       "      <td>Tokyo is the capital city of Japan and one of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tell me a joke.</td>\n",
       "      <td>Why don't programmers like nature? Too many bugs!</td>\n",
       "      <td>Programmers often use the term 'bug' to descri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When does water boil?</td>\n",
       "      <td>Water's boiling point is 100 degrees Celsius.</td>\n",
       "      <td>At standard atmospheric pressure (1 atm), wate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who painted the Mona Lisa?</td>\n",
       "      <td>Leonardo da Vinci painted the Mona Lisa.</td>\n",
       "      <td>The Mona Lisa is a portrait painting created b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question  \\\n",
       "0  What is the chemical symbol for gold?   \n",
       "1          What is the capital of Japan?   \n",
       "2                        Tell me a joke.   \n",
       "3                  When does water boil?   \n",
       "4             Who painted the Mona Lisa?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                        Gold chemical symbol is Au.   \n",
       "1                     The capital of Japan is Tokyo.   \n",
       "2  Why don't programmers like nature? Too many bugs!   \n",
       "3      Water's boiling point is 100 degrees Celsius.   \n",
       "4           Leonardo da Vinci painted the Mona Lisa.   \n",
       "\n",
       "                                             context  \n",
       "0  Gold is a chemical element with the symbol Au ...  \n",
       "1  Tokyo is the capital city of Japan and one of ...  \n",
       "2  Programmers often use the term 'bug' to descri...  \n",
       "3  At standard atmospheric pressure (1 atm), wate...  \n",
       "4  The Mona Lisa is a portrait painting created b...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [\n",
    "        \"What is the chemical symbol for gold?\",\n",
    "        \"Gold chemical symbol is Au.\",\n",
    "        \"Gold is a chemical element with the symbol Au and atomic number 79. It is a dense, soft, yellow metal highly valued for its rarity and conductivity.\"\n",
    "    ],\n",
    "    [\n",
    "        \"What is the capital of Japan?\",\n",
    "        \"The capital of Japan is Tokyo.\",\n",
    "        \"Tokyo is the capital city of Japan and one of the most populous metropolitan areas in the world.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Tell me a joke.\",\n",
    "        \"Why don't programmers like nature? Too many bugs!\",\n",
    "        \"Programmers often use the term 'bug' to describe an error in code, which is humorously extended to nature, which has literal bugs.\"\n",
    "    ],\n",
    "    [\n",
    "        \"When does water boil?\",\n",
    "        \"Water's boiling point is 100 degrees Celsius.\",\n",
    "        \"At standard atmospheric pressure (1 atm), water boils at 100 degrees Celsius or 212 degrees Fahrenheit.\"\n",
    "    ],\n",
    "    [\n",
    "        \"Who painted the Mona Lisa?\",\n",
    "        \"Leonardo da Vinci painted the Mona Lisa.\",\n",
    "        \"The Mona Lisa is a portrait painting created by the Italian Renaissance artist Leonardo da Vinci between 1503 and 1506.\"\n",
    "    ],\n",
    "    [\n",
    "        \"What’s the fastest animal on land?\",\n",
    "        \"The cheetah is the fastest land animal, capable of running up to 75 miles per hour.\",\n",
    "        \"Cheetahs are known for their speed and are the fastest land animals, reaching speeds up to 75 mph in short bursts covering distances up to 500 meters.\"\n",
    "    ],\n",
    "   \n",
    "]\n",
    "\n",
    "columns = [\"question\", \"answer\", \"context\"]\n",
    "\n",
    "\n",
    "eval_df = pd.DataFrame(data, columns=columns)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "OPENAI_API_KEY=\"YOUR_OPENAI_API_KEY\"  # Replace with your actual OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ea2f7",
   "metadata": {},
   "source": [
    "### Creating an Evaluation Dataset with Descriptors\n",
    "\n",
    "This section converts the dummy `pandas.DataFrame` into an `Evidently` `Dataset` and attaches multiple evaluation **descriptors** to analyze various aspects of the LLM responses.\n",
    "\n",
    "\n",
    "#### Description of Key Components\n",
    "\n",
    "- **`Dataset.from_pandas(...)`**: Converts the DataFrame into a format understood by Evidently.\n",
    "- **`data_definition=DataDefinition()`**: Placeholder that can be extended to define semantic roles of columns (e.g., prediction, reference).\n",
    "- **`descriptors=[...]`**: List of metrics to apply to each row in the dataset.\n",
    "\n",
    "#### Attached Descriptors\n",
    "\n",
    "| Descriptor | Purpose |\n",
    "|-----------|---------|\n",
    "| `NegativityLLMEval` | Detects negative tone or wording in the response. |\n",
    "| `PIILLMEval` | Identifies personally identifiable information (PII). |\n",
    "| `DeclineLLMEval` | Checks if the model declined to answer a question. |\n",
    "| `BiasLLMEval` | Flags biased or unfair language in the answer. |\n",
    "| `ToxicityLLMEval` | Measures toxic or harmful language. |\n",
    "| `ContextQualityLLMEval` | Assesses the quality of the provided context relative to the question. |\n",
    "| `ContextRelevance` | Evaluates how well the answer aligns with the context. |\n",
    "| `Sentiment` | Provides sentiment polarity (positive/neutral/negative). |\n",
    "| `TextLength` | Reports the length of the response. |\n",
    "| `DeclineLLMEval` (again with alias `Denials`) | Duplicate use for additional reporting under a different label. |\n",
    "\n",
    "\n",
    "> `include_score=True` ensures numeric scoring for quantitative evaluation.\n",
    "> `alias` helps assign custom names to descriptor outputs for clarity in results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c8484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = Dataset.from_pandas(\n",
    "    eval_df,\n",
    "    data_definition=DataDefinition(),\n",
    "    descriptors=[\n",
    "        NegativityLLMEval(\"answer\",include_score=True),\n",
    "        PIILLMEval(\"answer\",include_score=True),\n",
    "        DeclineLLMEval(\"answer\", include_score=True),\n",
    "        BiasLLMEval(\"answer\", include_score=True),\n",
    "        ToxicityLLMEval(\"answer\" , include_score=True),\n",
    "        ContextQualityLLMEval(\"context\", question=\"question\",include_score= True), \n",
    "        ContextRelevance(\"answer\", \"context\",alias=\"ContextRelevance\"), \n",
    "        Sentiment(\"answer\", alias=\"Sentiment\"),\n",
    "        TextLength(\"answer\", alias=\"Length\"),\n",
    "        DeclineLLMEval(\"answer\", alias=\"Denials\",include_score=True),]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090c3798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>Negativity</th>\n",
       "      <th>Negativity score</th>\n",
       "      <th>Negativity reasoning</th>\n",
       "      <th>PII</th>\n",
       "      <th>PII score</th>\n",
       "      <th>PII reasoning</th>\n",
       "      <th>Decline</th>\n",
       "      <th>...</th>\n",
       "      <th>Toxicity reasoning</th>\n",
       "      <th>ContextQuality</th>\n",
       "      <th>ContextQuality score</th>\n",
       "      <th>ContextQuality reasoning</th>\n",
       "      <th>ContextRelevance</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>Denials</th>\n",
       "      <th>Denials score</th>\n",
       "      <th>Denials reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the chemical symbol for gold?</td>\n",
       "      <td>Gold chemical symbol is Au.</td>\n",
       "      <td>Gold is a chemical element with the symbol Au ...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>The text provides factual information about th...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text provides information about the chemic...</td>\n",
       "      <td>OK</td>\n",
       "      <td>...</td>\n",
       "      <td>The text is factual and does not contain any h...</td>\n",
       "      <td>VALID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The text provides the chemical symbol for gold...</td>\n",
       "      <td>0.886829</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>27</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text provides factual information about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Japan?</td>\n",
       "      <td>The capital of Japan is Tokyo.</td>\n",
       "      <td>Tokyo is the capital city of Japan and one of ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text simply states a factual piece of info...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text provides information about the capita...</td>\n",
       "      <td>OK</td>\n",
       "      <td>...</td>\n",
       "      <td>The text simply states a factual piece of info...</td>\n",
       "      <td>VALID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The text clearly states that Tokyo is the capi...</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>30</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The statement 'The capital of Japan is Tokyo' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tell me a joke.</td>\n",
       "      <td>Why don't programmers like nature? Too many bugs!</td>\n",
       "      <td>Programmers often use the term 'bug' to descri...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.1</td>\n",
       "      <td>The text presents a light-hearted joke rather ...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The provided text is a joke about programmers ...</td>\n",
       "      <td>OK</td>\n",
       "      <td>...</td>\n",
       "      <td>The text is a light-hearted joke about program...</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text does not provide a joke, which is req...</td>\n",
       "      <td>0.774565</td>\n",
       "      <td>-0.3404</td>\n",
       "      <td>49</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text is a light-hearted joke about program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When does water boil?</td>\n",
       "      <td>Water's boiling point is 100 degrees Celsius.</td>\n",
       "      <td>At standard atmospheric pressure (1 atm), wate...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>The statement is factual and neither expresses...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text discusses a physical property of wate...</td>\n",
       "      <td>OK</td>\n",
       "      <td>...</td>\n",
       "      <td>The text presents a factual statement about wa...</td>\n",
       "      <td>VALID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The text provides clear and sufficient informa...</td>\n",
       "      <td>0.892115</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>45</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text provides factual information about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who painted the Mona Lisa?</td>\n",
       "      <td>Leonardo da Vinci painted the Mona Lisa.</td>\n",
       "      <td>The Mona Lisa is a portrait painting created b...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text presents a factual statement about Le...</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text does not contain any identifiable per...</td>\n",
       "      <td>OK</td>\n",
       "      <td>...</td>\n",
       "      <td>The text simply states a factual statement abo...</td>\n",
       "      <td>VALID</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The text clearly states that the Mona Lisa was...</td>\n",
       "      <td>0.873290</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>40</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The text states a fact about Leonardo da Vinci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question  \\\n",
       "0  What is the chemical symbol for gold?   \n",
       "1          What is the capital of Japan?   \n",
       "2                        Tell me a joke.   \n",
       "3                  When does water boil?   \n",
       "4             Who painted the Mona Lisa?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                        Gold chemical symbol is Au.   \n",
       "1                     The capital of Japan is Tokyo.   \n",
       "2  Why don't programmers like nature? Too many bugs!   \n",
       "3      Water's boiling point is 100 degrees Celsius.   \n",
       "4           Leonardo da Vinci painted the Mona Lisa.   \n",
       "\n",
       "                                             context Negativity  \\\n",
       "0  Gold is a chemical element with the symbol Au ...    UNKNOWN   \n",
       "1  Tokyo is the capital city of Japan and one of ...   POSITIVE   \n",
       "2  Programmers often use the term 'bug' to descri...   POSITIVE   \n",
       "3  At standard atmospheric pressure (1 atm), wate...    UNKNOWN   \n",
       "4  The Mona Lisa is a portrait painting created b...   POSITIVE   \n",
       "\n",
       "   Negativity score                               Negativity reasoning PII  \\\n",
       "0               0.5  The text provides factual information about th...  OK   \n",
       "1               0.0  The text simply states a factual piece of info...  OK   \n",
       "2               0.1  The text presents a light-hearted joke rather ...  OK   \n",
       "3               0.5  The statement is factual and neither expresses...  OK   \n",
       "4               0.0  The text presents a factual statement about Le...  OK   \n",
       "\n",
       "   PII score                                      PII reasoning Decline  ...  \\\n",
       "0        0.0  The text provides information about the chemic...      OK  ...   \n",
       "1        0.0  The text provides information about the capita...      OK  ...   \n",
       "2        0.0  The provided text is a joke about programmers ...      OK  ...   \n",
       "3        0.0  The text discusses a physical property of wate...      OK  ...   \n",
       "4        0.0  The text does not contain any identifiable per...      OK  ...   \n",
       "\n",
       "                                  Toxicity reasoning ContextQuality  \\\n",
       "0  The text is factual and does not contain any h...          VALID   \n",
       "1  The text simply states a factual piece of info...          VALID   \n",
       "2  The text is a light-hearted joke about program...        INVALID   \n",
       "3  The text presents a factual statement about wa...          VALID   \n",
       "4  The text simply states a factual statement abo...          VALID   \n",
       "\n",
       "  ContextQuality score                           ContextQuality reasoning  \\\n",
       "0                  1.0  The text provides the chemical symbol for gold...   \n",
       "1                  1.0  The text clearly states that Tokyo is the capi...   \n",
       "2                  0.0  The text does not provide a joke, which is req...   \n",
       "3                  1.0  The text provides clear and sufficient informa...   \n",
       "4                  1.0  The text clearly states that the Mona Lisa was...   \n",
       "\n",
       "  ContextRelevance Sentiment  Length Denials Denials score  \\\n",
       "0         0.886829    0.0000      27      OK           0.0   \n",
       "1         0.928000    0.0000      30      OK           0.0   \n",
       "2         0.774565   -0.3404      49      OK           0.0   \n",
       "3         0.892115    0.0000      45      OK           0.0   \n",
       "4         0.873290    0.0000      40      OK           0.0   \n",
       "\n",
       "                                   Denials reasoning  \n",
       "0  The text provides factual information about th...  \n",
       "1  The statement 'The capital of Japan is Tokyo' ...  \n",
       "2  The text is a light-hearted joke about program...  \n",
       "3  The text provides factual information about th...  \n",
       "4  The text states a fact about Leonardo da Vinci...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.as_dataframe().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e00edf",
   "metadata": {},
   "source": [
    "### Extracting Metric Results \n",
    "This code evaluates **only the first row** of the `eval_dataset` for demonstration purposes and extracts all **numeric descriptor scores** into a dictionary called `metric_results`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7eaa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negativity': 0.5, 'PII': 0.0, 'Decline': 0.0, 'Bias': 0.0, 'Toxicity': 0.0, 'ContextQuality': 1.0, 'ContextRelevance': 0.8868294358253479, 'Sentiment': 0.0, 'Denials': 0.0}\n"
     ]
    }
   ],
   "source": [
    "metric_results = {}\n",
    "row = eval_dataset.as_dataframe().iloc[0]\n",
    "for col, val in row.items():\n",
    "    if isinstance(val, (int, float)):\n",
    "        clean_col = col.replace(' score', '')\n",
    "        metric_results[clean_col] = float(val)\n",
    "print(metric_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41274d07",
   "metadata": {},
   "source": [
    "## How to get your subscription key for the TRACE Metrics API\n",
    "\n",
    "To access the TRACE Metrics API, you need a **subscription key**. Follow these steps:\n",
    "\n",
    "1. **Sign in to CognitiveView**  \n",
    "   Go to [app.cognitiveview.com](https://app.cognitiveview.com) and log in with your account credentials.\n",
    "\n",
    "2. **Navigate to System Settings**  \n",
    "   Once logged in, find the **System Settings** option in the main menu.\n",
    "\n",
    "3. **Generate and view your subscription key**  \n",
    "   - Inside **System Settings**, look for the section labeled **API Access** or **Subscription Key**.\n",
    "   - If a key has already been generated, you can copy it directly.\n",
    "   - If not, click the **Generate Key** button to create a new key.\n",
    "\n",
    "4. **Copy and save your subscription key**  \n",
    "   Keep this key secure. You’ll need to include it in your API requests for authentication.\n",
    "\n",
    "---\n",
    "\n",
    "## Posting Evaluation Metrics to TRACE Metrics API\n",
    "\n",
    "This script sends your evaluation metric results (for example, from DeepEval) to the TRACE Metrics API using an authenticated HTTP POST request.\n",
    "\n",
    "### Authentication\n",
    "\n",
    "- Use an **Authorization token** (`AUTH_TOKEN`) in the request header.\n",
    "- Include an **X-User-Id** header to identify the user making the request.\n",
    "\n",
    "---\n",
    "\n",
    "### Endpoint\n",
    "\n",
    "| Item         | Value                                                      |\n",
    "|--------------|-----------------------------------------------------------|\n",
    "| **Base URL** | `https://api.cognitiveview.com`                            |\n",
    "| **API Path** | `/cv/v1/metrics`                                          |\n",
    "| **Full URL** | `https://api.cognitiveview.com/cv/v1/metrics`             |\n",
    "\n",
    "---\n",
    "\n",
    "### Payload Structure\n",
    "\n",
    "#### `metric_metadata`\n",
    "\n",
    "Contains information about what you’re evaluating:\n",
    "- `application_name`: Name of the evaluated application.\n",
    "- `version`: Version of the application or model.\n",
    "- `provider`: The metric system or platform (for example, `deepeval`).\n",
    "- `use_case`: The business or functional domain (for example, `customer_support`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ec8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_metrics_to_TRACE_Metric_API(metric_results, auth_token, user_id):\n",
    "  \"\"\"\n",
    "  Posts Evidently metric results to the Trace Metric API.\n",
    "\n",
    "  Args:\n",
    "    metric_results (dict): Dictionary of computed metric scores.\n",
    "    auth_token (str): Authorization token for the API.\n",
    "    user_id (str): User ID for the API (default is \"C473421_T181751\").\n",
    "\n",
    "  Returns:\n",
    "    dict: Response JSON from the API.\n",
    "  \"\"\"\n",
    "  import requests\n",
    "\n",
    "  BASE_URL = \"https://api.cognitiveview.com\"\n",
    "  url = f\"{BASE_URL}/cv/v1/metrics\"\n",
    "\n",
    "  headers = {\n",
    "    \"Authorization\": auth_token,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-User-Id\": user_id,\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"metric_metadata\": {\n",
    "    \"application_name\": \"chat-application\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"url\": \"https://api.example.com/chat\",\n",
    "    \"provider\": \"Evidently\",\n",
    "    \"use_case\": \"transportation\"\n",
    "    },\n",
    "    \"metric_data\": {\n",
    "    \"Evidently\": metric_results\n",
    "    } \n",
    "  }\n",
    "\n",
    "  response = requests.post(url, headers=headers, json=payload)\n",
    "  print(f\"Status Code: {response.status_code}\")\n",
    "  try:\n",
    "    print(\"Response JSON:\", response.json())\n",
    "    return response.json()\n",
    "  except Exception:\n",
    "    print(\"Response Text:\", response.text)\n",
    "    return None\n",
    "\n",
    "# Example usage:\n",
    "AUTH_TOKEN = \"Your-Authorization-Token-Here\"  # Replace with your actual token\n",
    "user_id = \"user_id\"  # Replace with your actual user ID\n",
    "post_metrics_to_TRACE_Metric_API(metric_results,AUTH_TOKEN,user_id)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
